# python scripts/recon/train_learning_based.py
hydra:
  job:
    chdir: True    # change to output folder


wandb_project: lensless
seed: 0
start_delay: null

# Dataset
files:
  # -- using local dataset
  # dataset: /scratch/bezzam/DiffuserCam_mirflickr/dataset  # Simulated : "mnist", "fashion_mnist", "cifar10", "CelebA". Measure :"DiffuserCam"
  # celeba_root: null   # path to parent directory of CelebA: https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html
  # psf: data/psf/diffusercam_psf.tiff
  # diffusercam_psf: True

  # -- using huggingface dataset
  dataset: bezzam/DiffuserCam-Lensless-Mirflickr-Dataset-NORM
  huggingface_dataset: True
  huggingface_psf: psf.tiff

  # -- train/test split
  split_seed: null   # if null use train/test split from dataset
  n_files: null    # null to use all for both train/test
  test_size: null

  # -- processing parameters
  downsample: 2    # factor by which to downsample the PSF, note that for DiffuserCam the PSF has 4x the resolution
  downsample_lensed: 2
  input_snr: null    # adding shot noise at input (for measured dataset) at this SNR in dB
  vertical_shift: null
  horizontal_shift: null
  rotate: False
  save_psf: False
  crop: null
    # vertical: null
    # horizontal: null
  image_res: null   # for measured data, what resolution used at screen
  extra_eval: null  # dict of extra datasets to evaluate on

alignment: null
#   topright: null    # height, width
  # height: null

torch: True
torch_device: 'cuda'
device_ids: null    # for multi-gpu set list, e.g. [0, 1, 2, 3]
measure: null       # if measuring data on-the-fly

# test set example to visualize at the end of every epoch
eval_disp_idx: [0, 1, 2, 3, 4]

display:
  # Whether to plot results.
  plot: True
  # Gamma factor for plotting.
  gamma: null

# Whether to save intermediate and final reconstructions.
save: True

reconstruction:
  # Method: unrolled_admm, unrolled_fista
  method: unrolled_admm
  skip_unrolled: False
  init_processors: null   # model name
  init_pre: True   # if `init_processors`, set pre-procesor is available
  init_post: True   # if `init_processors`, set post-procesor is available

  # Hyperparameters for each method
  unrolled_fista: # for unrolled_fista
    # Number of iterations
    n_iter: 20
    tk: 1
    learn_tk: True
  unrolled_admm:
    # Number of iterations
    n_iter: 20
    # Hyperparameters
    mu1: 1e-4
    mu2: 1e-4
    mu3: 1e-4
    tau: 2e-4
  trainable_inv:
    K: 1e-4
  pre_process: 
    network : null  # UnetRes or DruNet or null
    depth : 2 # depth of each up/downsampling layer. Ignore if network is DruNet
    nc: null
    delay: null    # add component after this may epochs
    freeze: null
    unfreeze: null
  post_process: 
    network : null  # UnetRes or DruNet or null
    depth : 2 # depth of each up/downsampling layer. Ignore if network is DruNet
    nc: null
    delay: null    # add component after this may epochs
    freeze: null
    unfreeze: null
    train_last_layer: False

#Trainable Mask
trainable_mask:
  mask_type: null #Null or "TrainablePSF" or "AdafruitLCD"
  # "random" (with shape of config.files.psf) or "psf" (using config.files.psf)
  initial_value: psf
  grayscale: False
  mask_lr: 1e-3
  optimizer: Adam  # Adam, SGD... (Pytorch class)
  L1_strength: 1.0  #False or float

target: "object_plane"    # "original" or "object_plane" or "label"

#for simulated dataset
simulation:
  grayscale: False
  output_dim: null     # should be set if no PSF is used    
  # random variations
  object_height: 0.04   # range for random height or scalar
  flip: True # change the orientation of the object (from vertical to horizontal)
  random_shift: False
  random_vflip: 0.5
  random_hflip: 0.5
  random_rotate: False
  # these distance parameters are typically fixed for a given PSF
  # for DiffuserCam psf # for tape_rgb psf     
  scene2mask: 10e-2     # scene2mask: 40e-2       
  mask2sensor: 9e-3     # mask2sensor: 4e-3       
  # see waveprop.devices
  sensor: "rpi_hq"
  snr_db: 10
  # simulate different sensor resolution
  # output_dim: [24, 32]    # [H, W] or null
  # Downsampling for PSF
  downsample: 8
  # max val in simulated measured (quantized 8 bits)
  quantize: False   # must be False for differentiability
  max_val: 255

#Training

training:
  batch_size: 8
  epoch: 25
  eval_batch_size: 10
  metric_for_best_model: null   # e.g. LPIPS_Vgg, null does test loss
  save_every: null
  #In case of instable training
  skip_NAN: True
  clip_grad: 1.0
  crop_preloss: False  # crop region for computing loss, files.crop should be set

optimizer:
  type: Adam  # Adam, SGD... (Pytorch class)
  lr: 1e-4
  slow_start: False  #float how much to reduce lr for first epoch
  # Decay LR in step fashion: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html
  step: False     # int, period of learning rate decay. False to not apply
  gamma: 0.1      # float, factor for learning rate decay 
  
  
loss: 'l2'
# set lpips to false to deactivate. Otherwise, give the weigth for the loss (the main loss l2/l1 always having a weigth of 1)
lpips: 1.0
unrolled_output_factor: False   # whether to account for unrolled output in loss (there must post-processor)